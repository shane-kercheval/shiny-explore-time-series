---
title: "sandbox - time series"
author: "Shane Kercheval"
output:
    md_document:
    variant: markdown_github
toc: true
toc_depth: 4
---
    
```{r setup, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
library(knitr)
library(forecast)
# library(lubridate)
# library(tidyverse)
library(stringr)
# library(scales)
# library(ggrepel)
library(rtools)
library(fpp2)

options(scipen=999) # non-scientific notation
```

```{r, echo=FALSE}
set.seed(41)
s <- seq(from = 1, to = 100, by = 1) + 10 + rnorm(100, sd = 7)
set.seed(42)
t <- seq(from = 1, to = 100, by = 1) + 10 + rnorm(100, sd = 7)

t
plot(t)
```

```{r, echo=FALSE}
temp <- cbind(ts(s), ts(t))

temp[, 1]
```



```{r, echo=FALSE}
ts(t, start=2000, frequency = 12)
```

```{r, echo=FALSE}
tseries <- ts(t, start=2000, frequency = 4)
tseries
```

```{r, echo=FALSE}
plot(tseries)
```

```{r, echo=FALSE}
library(fpp2)
library(rtools)


class(a10)

as.matrix(a10)


data.frame(Y=as.matrix(a10), date=time(a10))

dataset <- a10
dataset <- melsyd
dataset <- elecdemand

colnames(elecdemand)

rt_explore_plot_correlations(as.data.frame(dataset))

asdf <- function(dataset) {
    
    categoric_dataset <- as.data.frame(dataset) %>% select_if(Negate(is.numeric))
    if(ncol(categoric_dataset) == 0) {

        return (data.frame())

    } else {

        return (rt_explore_categoric_summary(categoric_dataset))
    }
}

asdf(dataset)

library(dplyr)
rt_explore_numeric_summary(as.data.frame(dataset) %>% select_if(is.numeric))

categoric_dataset <- as.data.frame(dataset) %>% select_if(Negate(is.numeric))
ncol()
rt_explore_categoric_summary()

```


```{r}

paste0(start(dataset), collapse = ', ')
paste0(end(dataset), collapse = ', ')
frequency(dataset)

??seasonal.periods

attr(dataset,'methods')
showMethods(classes="msts")

pretty_dataset <- function(dataset) {

    classes <- class(dataset)
    if(length(classes) == 1 && classes == 'ts') {

        return (data.frame(date=time(dataset), value=as.matrix(dataset)))
        
    } else if (any(classes == 'mts') || any(classes == 'msts')) {
        
        return (cbind(data.frame(date = time(dataset)), as.data.frame(dataset)))
        
    } else {
        
        stopifnot(FALSE)
    }
}
pretty_dataset(dataset)
pretty_dataset(dataset=a10)
pretty_dataset(dataset=melsyd)
prett

class(a10)
any(class(melsyd) == 'mts')
class(visnights)


library(ggplot2)
#install.packages('ggfortify')
#install.packages('zoo')
library(ggfortify)
library(scales)
time(tseries)

visnights %>%
#    zoo() %>%
autoplot() +
    ggtitle('Autoplot') +
    xlab('Year') #+
    #scale_x_discrete(breaks=x_output$timestamp[brks])
    #scale_x_continuous(breaks=2000:2024) 
    #scale_x_date(breaks = date_breaks("year"), labels = date_format("%Y")) +
   # scale_x_date(breaks = date_breaks("5 years"), minor_breaks = date_breaks("1 years"), labels = date_format("%Y")) +
    #theme(axis.text.x = element_text(angle = 30, hjust = 1))
#    scale_x_yearqtr()


min(visnights)
min(melsyd, na.rm = TRUE)
```

```{r}
rt_explore_numeric_summary(a10)
rt_explore_numeric_summary(visnights)
rt_explore_correlations(visnights)

rt_explore_plot_time_series(a10)
```

```{r, echo=FALSE}
#install.packages('fpp2')
#library(fpp2)

a10
melsyd[!is.na(melsyd[, 'First.Class']), 'First.Class']
melsyd[, 'First.Class']
ts(melsyd[, 'First.Class'])

colnames(a10)
colnames(melsyd)


colnames(a10)
colnames(melsyd[, 'First.Class'])
as.numeric(a10)
as.numeric(melsyd[, 'First.Class'])

class(a10) == 'ts'
class(melsyd[, 'First.Class']) == 'ts'

as.data.frame()

is_ts <- function(x) {
    any(class(x) == 'ts')
}
temp <- as.data.frame(melsyd) 
attr(melsyd, "ts_type") <- 'single'
attr(melsyd, "ts_type")

any(class(melsyd[, 'First.Class']) == 'ts')


typeof(a10)
typeof(melsyd[, 'First.Class'])

start(elecdemand)
end(elecdemand)

dim(a10)
dim(melsyd[, 'First.Class'])
window(melsyd[, 'First.Class'], start=c(1990, 0))
window(melsyd[, 'First.Class'], start=NULL, end=NULL)

melsyd


window(melsyd[, 'First.Class'], start=1990, end=NULL)

s <- start(temp)
e <- end(temp[, 1])
f <- frequency(temp[, 1])
ts(as.numeric(temp[, 1]), start=s, end=e, frequency=4)

#temp[, 1] %>%
ts(as.numeric(temp[, 1]), start=s, end=e, frequency=f) %>%
#melsyd[, 'First.Class'] %>%
#window(start=c(1990, 0)) %>%
#a10 %>%
temp %>%
    autoplot() +
    ggtitle('Autoplot') 
#    xlab('') 
    #scale_x_discrete(breaks=x_output$timestamp[brks])
    #scale_x_continuous(breaks=0:100) 
    #scale_x_date(date_breaks = "1 year")
    scale_x_date(breaks = date_breaks("1 years"), labels = date_format("%Y"))
    #scale_x_date(breaks = c(198))


, labels = date_format("%Y")) +
    #scale_x_date(breaks = date_breaks("5 years"), minor_breaks = date_breaks("1 years"), labels = date_format("%Y")) +
    theme(axis.text.x = element_text(angle = 30, hjust = 1))
#    scale_x_yearqtr()
```


```{r}
beer_data <- ausbeer
beer_data <- window(beer_data, start=1992, end=c(2007, 4))

autoplot(beer_data) +
    autolayer(meanf(beer_data, h=11), series='Mean', PI=FALSE)

```

```{r}
dataset <- a10
forecast_model <- forecast(dataset, h=24)
comment(forecast_model) <- 'Forecast'

model_list <- list(forecast_model)
forecast_model <- naive(dataset, h=6)
comment(forecast_model) <- 'Naive'
#residuals(forecast_model)
model_list <- c(model_list, list(forecast_model))


resid_stats <- map(model_list, ~ {
    resids <- residuals(.)
    resid_mean <- mean(resids, na.rm = TRUE)
    resid_stan_dev <- sd(resids, na.rm = TRUE)
        
    return (data.frame(Model=comment(.),
                       Mean=resid_mean,
                       `Standard Deviation`=resid_stan_dev,
                       `Coefficient of Variation`=resid_stan_dev / resid_mean))
})

resid_stats_df <- do.call("rbind", resid_stats)
colnames(resid_stats_df) <- str_replace_all(colnames(resid_stats_df), '\\.', ' ')
resid_stats_df
```


```{r}
library(forecast)

dataset <- a10
forecast_model <- forecast(dataset, h=24)

s <- start(forecast_model$mean)
e <- end(forecast_model$mean)
f <- frequency(forecast_model$mean)

df_forecast_model <- as.data.frame(forecast_model)
ts_forecast <- ts(df_forecast_model$`Point Forecast`, start = s, end=e, frequency = f)

dataset %>%
    autoplot() + 
    autolayer(forecast_model,
              series='Auto',
              PI=TRUE) + 
    geom_point() +
    geom_text(aes(label=round(as.numeric(dataset), 0)), check_overlap=TRUE, vjust=1, hjust=1) +
    geom_point(data= ts_forecast) + 
    geom_text(data= ts_forecast, aes(label=round(ts_forecast, 1)), check_overlap=TRUE, vjust=0, hjust=0, color='blue')

```

```{r}
monthdays(milk)
frequency(milk) # 12 month

monthdays(ausbeer)
frequency(ausbeer) #  4 quarter

monthdays(melsyd)
frequency(melsyd) #  weekly


dframe <- cbind(Monthly = milk, 
                DailyAverage= milk / mont)



create_daily_average <- function(dataset) {
    
    freq <- frequency(dataset)
    
    if(freq == 12 || freq == 4) {  # monthly or quarterly

        return (dataset / monthdays(dataset))

    } else if (freq == 52) {  # weekly
    
        return (dataset / 7)

    } else {

        stopifnot(FALSE)
    }
}

create_daily_average(milk)
create_daily_average(ausbeer)
create_daily_average(melsyd)

log(milk+1, base=exp(1))
log(milk+1, base=2)


lambda <- BoxCox.lambda(milk)
BoxCox(milk, lambda = lambda)
```

```{r}
cv_mse <- function(cv_result) {

    return (colMeans(cv_result^2, na.rm = TRUE))
}

cv_rmse <- function(cv_result) {

    return (map_dbl(cv_mse(cv_result), ~ sqrt(.)))
}

cv_mae <- function(cv_result) {
    
    return (colSums(abs(cv_result), na.rm = TRUE) / nrow(cv_result))
}

cv_result <- tsCV(milk, forecastfunction = naive, h=8)
results <- rbind(NULL, cv_mae(cv_result))

cv_result <- tsCV(milk, forecastfunction = rwf, drift=TRUE, h=8)
results <- rbind(results, cv_mae(cv_result))
steps_ahead <- colnames(results)
results <- as.data.frame(results)

results$method <- c('rwf', 'naive')

results %>% 
    gather(key, value, -method) %>%
    mutate(key = factor(key, levels = steps_ahead)) %>%
    ggplot(aes(x=key, y=value, color=method, group=method)) +
        geom_line() +
        geom_point() +
        ylab('MAE') + xlab('Steps Ahead') +
        geom_text(aes(label=round(value, 1)), check_overlap=TRUE, vjust=1, hjust=1)
```

```{r}
tsCV(goog200, forecastfunction = rwf, drift=TRUE, lambda=1, h=8)
tsCV(goog200, forecastfunction = rwf, drift=TRUE, lambda=0, h=8)
```

```{r}
lm_results <- tslm(Consumption ~ Income, data=uschange)
summary(lm_results)
```

```{r}
lm_results <- tslm('Consumption ~ Income', data=uschange)
summary(lm_results)
```

```{r}
?marathon
fitted(forecast(goog))
```

```{r}


independent_variables <- c('trend', 'season')
dataset <- melsyd

dataset_variables <- independent_variables[! independent_variables %in% c('trend', 'season')]

if(length(dataset_variables) == 0) {

    indexes_to_remove <- which(!complete.cases(dataset))

} else {
    
    indexes_to_remove <- which(!complete.cases(dataset[, dataset_variables]))
}

na.omit(dataset)
```


```{r}
# NOTE: we have to lag at least 1 value, **unless we are using trend/season**
# if we forecast prediction of prediction, we only have to lag1
# if we forecast with actual values, we have to lag as far back as we want to predict (i.e. predict 10 periods in future, lag at least 10 periods behind)

# MAKE BOTH METHODS WORK ON SINGLE/MULTI variable datasets
ex_ante_regression <- TRUE

num_lags <- 20
predict_horizon <- 10

if(ex_ante_regression) {

    ex_ante_horizon <- predict_horizon
    
} else {

    ex_ante_horizon <- NULL
}


stopifnot(num_lags >= predict_horizon)


###################### VISNIGHTS################
# dataset <- visnights
# if(!is.null(num_lags)) {

#     dataset <- rt_ts_create_lagged_dataset(dataset, lag_variables=c('NSWNthCo'), keep_variables=c('NSWMetro'), num_lags = num_lags)
# }

# dependent_variable = 'NSWMetro'
# independent_variables = c('trend', 'season', colnames(dataset))
# 
# reg_formula <- rt_ts_lm_build_formula(dependent_variable = dependent_variable,
#                                       independent_variables = independent_variables,
#                                       ex_ante_horizon = ex_ante_horizon)

###################### A10 #####################
dataset <- a10
dependent_variable = 'Loaded Data'

independent_variables = c('trend', 'season', colnames(dataset))

single_time_series_variable_name <- "Loaded Data"
if(dependent_variable == single_time_series_variable_name) {

        dependent_variable <- 'dataset'
}


trend_season <- independent_variables[independent_variables %in% c('trend', 'season')]
column_names <- c(dependent_variable, independent_variables)
c(c(), column_names[! column_names %in% dependent_variable])


# two ways to make predictions.. can use predictions of predictions, or, can use lag values at least as farback as we want to forecast e.g. forecast 4 months we need to lag data by 4 months
```

```{r}
# lag
lagged_data <- cbind(
    NSWMetro=visnights[, 'NSWMetro'],
    NSWNthCo=visnights[, 'NSWNthCo'],
    Lag1_NSWNthCo=stats::lag(visnights[, 'NSWNthCo'], -1),
    Lag2_NSWNthCo=stats::lag(visnights[, 'NSWNthCo'], -2),
    Lag3_NSWNthCo=stats::lag(visnights[, 'NSWNthCo'], -3),
    Lag4_NSWNthCo=stats::lag(visnights[, 'NSWNthCo'], -4))

# na.omit will remove the NAs at the beginning of the dataset but will also remove the NAs at the end of the 
# dataset which is needed to we restrict the training to the original time horizon i.e. ending period
end(visnights) 
end(lagged_data)

training_data <- na.omit(lagged_data)
end(visnights) 
end(lagged_data)
end(training_data)

#dataset <- visnights
ts_model <- tslm(NSWMetro ~ trend + season + Lag4_NSWNthCo, data = training_data)
#summary(ts_model)
# forecast automatically gives trend/season as can be observed with the ts_forecast results i.e. row names

# now we can only predict 4 periods ahead because we lagged 4 periods
predict_horizon <- 4
num_periods <- nrow(lagged_data) ##### NOTE: need to use nrow or length depending on if it is multi vs single variable dataset
new_data <- subset(lagged_data, start=num_periods - predict_horizon + 1)

new_data2 <- as.data.frame(new_data) %>% select(Lag4_NSWNthCo)

ts_forecast <- forecast(ts_model, newdata = new_data2)
#ts_forecast <- forecast(ts_model, xreg = as.data.frame(new_data) %>% select(-'NSWMetro', -'NSWNthCo', -'Lag1_NSWNthCo'))
ts_forecast
#rownames(as.data.frame(ts_forecast)

autoplot(lagged_data[, 'NSWMetro']) +
    autolayer(fitted(ts_model), series = 'Regression') +
    autolayer(ts_forecast, series = 'Regression') + 
    labs(caption='Confidence level is misleading, because we are using predictions of predictions')

```



```{r}
library(seasonal)

a10 %>% seas(x11="") %>% autoplot() + ggtitle("X11 Decomposition")



summary(window(austourists, start=2005) %>% ets(damped=TRUE))

?ets
```




```{r}
a10 %>%
    autoplot() +
    autolayer(ets(a10) %>% forecast(h=24))


install.packages('colorspace')
```

```{r fig.height=7, fig.width=10}
regression_decomposition <- function(dataset, loess_span=NULL) {

    regression <- tslm(dataset ~ trend + season)
    reg_residuals <- residuals(regression)
    # trend <- Intercept + Trend ... seq_along creates a sequence of trends corresponding to the number of data-points in local_dataset
    trend <- coef(regression)[1] + coef(regression)['trend'] * seq_along(dataset)
    # extract season before we change trend/residuals from loess, if applicable
    season <- dataset - trend - reg_residuals

    if(!is.null(loess_span)) {
        
        temp_data <- data.frame(trend=1:length(dataset), data=as.numeric(dataset))
        loess_trend <- loess(data ~ trend, data=temp_data, span=loess_span)
        
        # get new curved trend
        trend <- predict(loess_trend)
        # # the seasonal components may throw off the trend (e.g. reference season is 0 and all the rest are negative);
        # # so lets move the trend up/down by the median
        # adjustment <- median(season) * -1
        # trend <- trend - adjustment

        # recalculate residuals based on new trend and old season
        reg_residuals <- dataset - trend - season
    } else {
#        season <- dataset - trend - reg_residuals
        # the seasonal components may throw off the trend (e.g. reference season is 0 and all the rest are negative);
        # so lets move the trend up/down by the median
        adjustment <- median(season) * -1
        trend <- trend - adjustment
    }

    return (cbind(
        data = dataset,
        trend = trend,
        season = dataset - trend - reg_residuals,
        remainder = reg_residuals
    ))
}
dataset <- log(a10)
components <- regression_decomposition(dataset = dataset, loess_span = NULL)
# create decomposition graph
autoplot(components, facet=TRUE, scales = "fixed") + ggtitle("Trend/Season Regression Decomposition")


# create a ts object of the trend
ts_trend <- ts(components[, 'trend'],
               start=start(dataset),
               frequency = frequency(dataset))
trend_layer <- autolayer(ts_trend, series="Trend")

# calculate the seasonally adjusted values by subtracting the seasonal component from the dataset.
adjust_df <- dataset - components[,'season']
seas_adj_layer <- autolayer(adjust_df, series="Seasonally Adjusted")

dataset %>% autoplot(series="Data") + 
    autolayer(components[,'trend'], series="Trend") +
    autolayer(components[,'trend'] + components[,'season'], series="Fit") +
    # trend_layer + 
    seas_adj_layer
```

```{r fig.height=7, fig.width=10}

dataset <- ts(c(...),
            start=2017,
            frequency = 12)
components <- regression_decomposition(dataset = dataset, loess_span = 1)
# create decomposition graph
autoplot(components, facet=TRUE, scales = "fixed") + ggtitle("Trend/Season Regression Decomposition")


# create a ts object of the trend
ts_trend <- ts(components[, 'trend'],
               start=start(dataset),
               frequency = frequency(dataset))
trend_layer <- autolayer(ts_trend, series="Trend")

# calculate the seasonally adjusted values by subtracting the seasonal component from the dataset.
adjust_df <- dataset - components[,'season']
seas_adj_layer <- autolayer(adjust_df, series="Seasonally Adjusted")

dataset %>% autoplot(series="Data") + 
    autolayer(components[,'trend'], series="Trend") +
    #autolayer(components[,'trend'] + components[,'season'], series="Fit") +
    # trend_layer + 
    seas_adj_layer +
    scale_colour_manual(values=c('gray', 'blue', 'red'),
                        breaks=c('Data', 'Seasonally Adjusted', 'Trend'))
```



```{r fig.height=7, fig.width=10}
# doesn't work that great
loess_decomposition <- function(dataset) {
    
    temp_data <- data.frame(trend=1:length(dataset), season=as.numeric(cycle(dataset)), data=as.numeric(dataset))
 
    loess_trend <- loess(data ~ trend, data=temp_data, span=1)
    loess_season <- loess(data ~ trend + season, data=temp_data, span=0.5)
    # summary(loess_results)
    # temp_data$predictions <- predict(loess_results)
    # temp_data %>%
    #     select(-season) %>%
    #     gather(type, value, -trend) %>%
    # ggplot(aes(x = trend, y=value, color=type)) +
    #     geom_line()

    # trend <- Intercept + Trend ... seq_along creates a sequence of trends corresponding to the number of data-points in local_dataset
    trend <- predict(loess_trend)
    season <- dataset - trend - residuals(loess_season)
    
    # the seasonal components may throw off the trend (e.g. reference season is 0 and all the rest are negative);
    # so lets move the trend up/down by the median
    adjustment <- median(season) * -1
    trend <- trend - adjustment
    
    return (cbind(
        data = dataset,
        trend = trend,
        season = dataset - trend - residuals(loess_season),
        remainder = residuals(loess_season)
    ))
}

dataset <- log(a10)
components <- loess_decomposition(dataset = dataset)
# create decomposition graph
autoplot(components, facet=TRUE, scales = "fixed") + ggtitle("Trend/Season Regression Decomposition")


# create a ts object of the trend
ts_trend <- ts(components[, 'trend'],
               start=start(dataset),
               frequency = frequency(dataset))
trend_layer <- autolayer(ts_trend, series="Trend")

# calculate the seasonally adjusted values by subtracting the seasonal component from the dataset.
adjust_df <- dataset - components[,'season']
seas_adj_layer <- autolayer(adjust_df, series="Seasonally Adjusted")

dataset %>% autoplot(series="Data") + 
    autolayer(components[,'trend'], series="Trend") +
    #autolayer(components[,'trend'] + components[,'season'], series="Fit") +
    # trend_layer + 
    seas_adj_layer +
    scale_colour_manual(values=c('gray', 'blue', 'red'),
                        breaks=c('Data', 'Seasonally Adjusted', 'Trend'))
```